# -*- coding: utf-8 -*-
"""TrainDelayPrediction_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nOo0R_jmFowxDvBshtDipla5a7HvyroK
"""

from google.colab import drive
drive.mount('/content/drive')

data_file_path = "drive/My Drive/Colab Notebooks/data/Historical_Train_Operation_Dataset/combined_Final.xlsx"
import pandas as pd
column_names = ["TrainNumber", "PrimaryDelay", "DepTime", "ArrTime", "TotalMargin", "SpeedLimit"]
data_labels = pd.read_excel(data_file_path, "combined_Final", usecols = "B", squeeze = "True")
data_train_index = pd.read_excel(data_file_path, "combined_Final", usecols = "A")
data_numerical_features = pd.read_excel(data_file_path, "combined_Final", usecols = "C:F, FL")
data_onehot_rolling_stock = pd.read_excel(data_file_path, "combined_Final", usecols = "G:O")
data_onehot_route = pd.read_excel(data_file_path, "combined_Final", usecols = "P:FK")

list_data_labels = data_labels.values.tolist()
list_data_train_index = data_train_index.values.tolist()
list_data_numerical_features = data_numerical_features.values.tolist()
list_data_onehot_rolling_stock = data_onehot_rolling_stock.values.tolist()

print(list_data_labels)
print(list_data_train_index)
print(list_data_numerical_features)
print(list_data_onehot_rolling_stock)
print(data_onehot_route)

def categorize_labels(l):
    categorized_labels = []
    for i in l:
        if i == 0.0:
            i = "0"
        elif i >= 1.0 and i <= 6.0:
            i = "1"
        elif i > 6.0 and i <= 11.0:
            i = "2"
        elif i > 11.0 and i <= 16.0:
            i = "3"
        else:
            i = "4"
        categorized_labels.append(i)
    return categorized_labels

def remove_comma(o):
    onehot_code_after_removed_comma = []
    for i in o:
        onehot_code = []
        onehot_code.append("".join("%s"%id for id in i))
        onehot_code_after_removed_comma.append(onehot_code)
    return onehot_code_after_removed_comma

def bar(x, columns):
    return ",".join(list(columns[x]))

def route_tiploc_code(route):
    cols = route.columns
    departure_sta = data_onehot_route.apply(lambda x: x == -5)
    list_departure_station = departure_sta.apply(lambda x: bar(x, cols), axis = 1).tolist()

    intermediate_sta = data_onehot_route.apply(lambda x: x == 1)
    list_intermediate_station = intermediate_sta.apply(lambda x: bar(x, cols), axis = 1).tolist()

    terminal_sta = data_onehot_route.apply(lambda x: x == 5)
    list_terminal_station = terminal_sta.apply(lambda x: bar(x, cols), axis = 1).tolist()

    return list_departure_station, list_intermediate_station, list_terminal_station

categorized_labels_list = categorize_labels(list_data_labels)
print(categorized_labels_list)

removed_comma_onehot_list = remove_comma(list_data_onehot_rolling_stock)
print(removed_comma_onehot_list)

list_departure_station, list_intermediate_station, list_terminal_station = route_tiploc_code(data_onehot_route)



for idx in range(len(list_departure_station)):
    if list_departure_station[idx] == "EDINBUR,HAYMRKT":
        list_departure_station[idx] = "EDINBUR & HAYMRKT"
    elif list_departure_station[idx] == "GLGC   ,MOTHRWL":
        list_departure_station[idx] = "GLGC & MOTHRWL"
    elif list_departure_station[idx] == "DWBY   ,YORK   ":
        list_departure_station[idx] = "DWBY & YORK"

for idx in range(len(list_terminal_station)):
    if list_terminal_station[idx] == "EDINBUR,HAYMRKT":
        list_terminal_station[idx] = "EDINBUR & HAYMRKT"
    elif list_terminal_station[idx] == "GLGC   ,MOTHRWL":
        list_terminal_station[idx] = "GLGC & MOTHRWL"
    elif list_terminal_station[idx] == "DWBY   ,YORK   ":
        list_terminal_station[idx] = "DWBY & YORK"


print(list_departure_station)
print(list_terminal_station)

from pandas import DataFrame
final_labels = DataFrame(categorized_labels_list, columns = ["PrimaryDelayLevel"])
final_onehot_rolling_stock = DataFrame(removed_comma_onehot_list, columns = ["OnehotofRollingStock"])
final_departure_station = DataFrame(list_departure_station, columns = ["DepartureStation"])
final_intermediate_station = DataFrame(list_intermediate_station, columns = ["IntermediateStations"])
final_terminal_station = DataFrame(list_terminal_station, columns = ["TerminalStation"])
final_numerical_features = DataFrame(list_data_numerical_features, columns = ["DepTime", "ArrTime", "TotalMargin", "SpeedLimit", "PassengerFlow"])

result = final_numerical_features.join(final_onehot_rolling_stock)
result = result.join(final_departure_station)
result = result.join(final_intermediate_station)
result = result.join(final_terminal_station)

from sklearn.preprocessing import LabelEncoder
from collections import Counter
y = np.array(categorized_labels_list)
y = np.ravel(y)
labelencoder = LabelEncoder()
y = labelencoder.fit_transform(y)
counter = Counter(y)
print(counter)



from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2)
dataset_train = X_train.join(y_train)
dataset_test = X_test.join(y_test)

dataset_test.head(n = 10)

import numpy as np
import pandas as pd
import csv

def add_q(s):#加上单引号
    try:
        if np.isnan(s):
            return('\' \'')
    except TypeError:
        res = ['\'']
        s0 = list(s)
        for i in s0:
            res.append(i)
        res.append('\'')
        return(''.join(res))


for i in dataset_train.index:
    dataset_train.loc[i, 'DepartureStation'] = add_q(dataset_train.loc[i, 'DepartureStation'])
    dataset_train.loc[i, 'IntermediateStations'] = add_q(dataset_train.loc[i, 'IntermediateStations'])
    dataset_train.loc[i, 'TerminalStation'] = add_q(dataset_train.loc[i, 'TerminalStation'])

for i in dataset_test.index:
    dataset_test.loc[i, 'DepartureStation'] = add_q(dataset_test.loc[i, 'DepartureStation'])
    dataset_test.loc[i, 'IntermediateStations'] = add_q(dataset_test.loc[i, 'IntermediateStations'])
    dataset_test.loc[i, 'TerminalStation'] = add_q(dataset_test.loc[i, 'TerminalStation'])

dataset_train.to_csv('drive/My Drive/Colab Notebooks/data/Historical_Train_Operation_Dataset/dataset_train4.csv', index = False)
dataset_test.to_csv('drive/My Drive/Colab Notebooks/data/Historical_Train_Operation_Dataset/dataset_test4.csv', index = False)